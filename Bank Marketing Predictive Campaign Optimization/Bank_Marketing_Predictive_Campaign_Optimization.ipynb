{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Summary\n",
        "[Bank Marketing dataset](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing) hosted on the UCI machine learning repository.\n",
        "\n",
        "For the banking industry, an important task is to market their products (e.g., a term deposit or a credit card) to potential customers. However, such tasks are usually challenging as banks need to cautiously balance the cost of large-scale marketing campaigns and the profit of signing up more customers.\n",
        "\n",
        "To address this issue, machine learning models have been widely adopted by the banking industry to identify potential customers and improve marketing effectiveness. The task is to develop machine learning models to predict whether a customer would sign up a term deposit using various features collected by a bank. Evaluate the performance of each model and recommend the most preferred model to the stakeholders in the marketing department.\n",
        "\n",
        "The `bank-train.csv` includes information on 32158 customers and the `bank-test.csv` includes information on another 8040 customers. For both datasets, there are 11 features that you can use for prediction. Below we list the detailed definitions for each feature:\n",
        "* age: age of the customer\n",
        "* housing: whether the customer has housing loan (0 for no; 1 for yes)\n",
        "* loan: whether the customer has personal loan (0 for no; 1 for yes)\n",
        "* contact: contact communication type (0 for cellular; 1 for telephone)\n",
        "* campaign: number of contacts performed during this campaign and for this customer\n",
        "* previous: number of contacts performed before this campaign and for this customer\n",
        "* emp.var.rate: employment variation rate - quarterly indicator\n",
        "* cons.price.idx: consumer price index - monthly indicato\n",
        "* cons.conf.idx: consumer confidence index - monthly indicator\n",
        "* euribor3m: euribor 3 month rate - daily indicator\n",
        "* nr.employed: number of employees - quarterly indicator\n",
        "\n",
        "The label we are going to predict has the name `y`, which indicates whether the customer signed up for the term deposit or not (0 for no; 1 for yes).\n"
      ],
      "metadata": {
        "id": "AzDlcbWo0nUb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmxUwJOOzvsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee0db93-4bb8-4362-8a64-094ee03a134a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bank-test.csv', <http.client.HTTPMessage at 0x7f4a671550d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve('https://drive.google.com/uc?export=download&id=16ECL47eCqWvWvXFZWxQak06L93oeUMP-',\n",
        "            'bank-train.csv')\n",
        "urlretrieve('https://drive.google.com/uc?export=download&id=1xDumIeMWoI4w82YKEvhflwZLSzqHOq-f',\n",
        "            'bank-test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Import and Process Data\n"
      ],
      "metadata": {
        "id": "wBFvCLWkuhRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the dataset\n",
        "data = pd.read_csv('bank-train.csv', sep=',')\n",
        "data_test = pd.read_csv('bank-test.csv', sep=',')\n",
        "\n",
        "# show the dataset\n",
        "## list the shape of the dataset in training\n",
        "print('Shape of the dataset: ')\n",
        "print(data.shape)\n",
        "print()\n",
        "\n",
        "## list the shape of the dataset in testing\n",
        "print('Shape of testing dataset')\n",
        "print(data_test.shape)\n",
        "print()\n",
        "\n",
        "## summarize the training dataset\n",
        "print('Summary of the dataset:')\n",
        "print(data.describe())\n",
        "print()\n",
        "\n",
        "## summarize the testing dataset\n",
        "print('Summary of the dataset:')\n",
        "print(data_test.describe())\n",
        "print()\n",
        "\n",
        "\n",
        "# create training data and labels\n",
        "X = data.drop(columns='y')\n",
        "y = data['y']\n",
        "\n",
        "# create  testing data and labels\n",
        "X_t = data_test.drop(columns='y')\n",
        "y_t = data_test['y']\n",
        "\n"
      ],
      "metadata": {
        "id": "85vshgSzug3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe3c16a-b617-44e6-f5bb-d505435e55b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset: \n",
            "(32158, 12)\n",
            "\n",
            "Shape of testing dataset\n",
            "(8040, 12)\n",
            "\n",
            "Summary of the dataset:\n",
            "                age       housing          loan       contact      campaign  \\\n",
            "count  32158.000000  32158.000000  32158.000000  32158.000000  32158.000000   \n",
            "mean      40.034175      0.537813      0.156695      0.363331      2.576870   \n",
            "std       10.456159      0.498576      0.363519      0.480967      2.806039   \n",
            "min       17.000000      0.000000      0.000000      0.000000      1.000000   \n",
            "25%       32.000000      0.000000      0.000000      0.000000      1.000000   \n",
            "50%       38.000000      1.000000      0.000000      0.000000      2.000000   \n",
            "75%       47.000000      1.000000      0.000000      1.000000      3.000000   \n",
            "max       98.000000      1.000000      1.000000      1.000000     43.000000   \n",
            "\n",
            "           previous  emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
            "count  32158.000000  32158.000000    32158.000000   32158.000000   \n",
            "mean       0.171466      0.080251       93.573651     -40.509273   \n",
            "std        0.492331      1.571759        0.578416       4.638589   \n",
            "min        0.000000     -3.400000       92.201000     -50.800000   \n",
            "25%        0.000000     -1.800000       93.075000     -42.700000   \n",
            "50%        0.000000      1.100000       93.749000     -41.800000   \n",
            "75%        0.000000      1.400000       93.994000     -36.400000   \n",
            "max        7.000000      1.400000       94.767000     -26.900000   \n",
            "\n",
            "          euribor3m   nr.employed             y  \n",
            "count  32158.000000  32158.000000  32158.000000  \n",
            "mean       3.619290   5167.012292      0.112196  \n",
            "std        1.735518     72.298096      0.315612  \n",
            "min        0.634000   4963.600000      0.000000  \n",
            "25%        1.344000   5099.100000      0.000000  \n",
            "50%        4.857000   5191.000000      0.000000  \n",
            "75%        4.961000   5228.100000      0.000000  \n",
            "max        5.045000   5228.100000      1.000000  \n",
            "\n",
            "Summary of the dataset:\n",
            "               age      housing         loan      contact     campaign  \\\n",
            "count  8040.000000  8040.000000  8040.000000  8040.000000  8040.000000   \n",
            "mean     39.992537     0.532463     0.150373     0.364552     2.531343   \n",
            "std      10.286550     0.498976     0.357459     0.481334     2.596756   \n",
            "min      17.000000     0.000000     0.000000     0.000000     1.000000   \n",
            "25%      32.000000     0.000000     0.000000     0.000000     1.000000   \n",
            "50%      38.000000     1.000000     0.000000     0.000000     2.000000   \n",
            "75%      47.000000     1.000000     0.000000     1.000000     3.000000   \n",
            "max      95.000000     1.000000     1.000000     1.000000    33.000000   \n",
            "\n",
            "          previous  emp.var.rate  cons.price.idx  cons.conf.idx    euribor3m  \\\n",
            "count  8040.000000   8040.000000     8040.000000    8040.000000  8040.000000   \n",
            "mean      0.177488      0.084540       93.576285     -40.502189     3.625385   \n",
            "std       0.500991      1.565775        0.577336       4.594035     1.729582   \n",
            "min       0.000000     -3.400000       92.201000     -50.800000     0.634000   \n",
            "25%       0.000000     -1.800000       93.075000     -42.700000     1.344000   \n",
            "50%       0.000000      1.100000       93.596500     -41.800000     4.857000   \n",
            "75%       0.000000      1.400000       93.994000     -36.400000     4.961000   \n",
            "max       6.000000      1.400000       94.767000     -26.900000     5.045000   \n",
            "\n",
            "       nr.employed            y  \n",
            "count  8040.000000  8040.000000  \n",
            "mean   5167.201629     0.115050  \n",
            "std      71.955317     0.319102  \n",
            "min    4963.600000     0.000000  \n",
            "25%    5099.100000     0.000000  \n",
            "50%    5191.000000     0.000000  \n",
            "75%    5228.100000     0.000000  \n",
            "max    5228.100000     1.000000  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Apply Machine Learning Classification Methods\n",
        "In this section, we train and evaluate various machine learning classification methods."
      ],
      "metadata": {
        "id": "c7Q2zLvju5mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,\\\n",
        "    precision_score, f1_score, roc_auc_score\n",
        "\n",
        "# Training the dataset\n",
        "knn = KNeighborsClassifier(n_neighbors=5)           # K = 5\n",
        "knn.fit(X, y)                                       # fit the model\n",
        "knn_pred_t = knn.predict(X_t)                       # make predictions\n",
        "knn_score_t = knn.predict_proba(X_t)                # get prediction scores\n",
        "\n",
        "## print the predicted labels\n",
        "print('Predicted labels testing:')\n",
        "print(knn_pred_t)\n",
        "print()\n",
        "\n",
        "## print the prediction scores\n",
        "print('Predicted scores testing:')\n",
        "print(knn_score_t)\n",
        "print()\n",
        "\n",
        "\n",
        "# calculate prediction performance\n",
        "print('Confusion Matrix testing:')\n",
        "knn_conf_mat = confusion_matrix(y_t, knn_pred_t)\n",
        "print(knn_conf_mat)\n",
        "print()\n",
        "\n",
        "## accuracy\n",
        "knn_acc = accuracy_score(y_t, knn_pred_t)\n",
        "print('Prediction accuracy testing dataset: {:.4f}'.format(knn_acc))\n",
        "\n",
        "## recall\n",
        "knn_recall = recall_score(y_t, knn_pred_t)\n",
        "print('Prediction recall testing dataset: {:.4f}'.format(knn_recall))\n",
        "\n",
        "## precision\n",
        "knn_precision = precision_score(y_t, knn_pred_t)\n",
        "print('Prediction precision testing dataset: {:.4f}'.format(knn_precision))\n",
        "\n",
        "## F1 score\n",
        "knn_f1 = f1_score(y_t, knn_pred_t)\n",
        "print('Prediction F1 testing dataset: {:.4f}'.format(knn_f1))\n",
        "\n",
        "## AUC-ROC\n",
        "knn_auc = roc_auc_score(y_t, knn_score_t[:, 1])\n",
        "print('AUC-ROC testing dataset: {:.4f}'.format(knn_auc))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCkjtkb2jv2v",
        "outputId": "86ec90c3-4c6d-4299-ee83-5ef2745d2baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels testing:\n",
            "[0 0 0 ... 0 0 0]\n",
            "\n",
            "Predicted scores testing:\n",
            "[[1.  0. ]\n",
            " [0.8 0.2]\n",
            " [0.6 0.4]\n",
            " ...\n",
            " [1.  0. ]\n",
            " [0.8 0.2]\n",
            " [0.8 0.2]]\n",
            "\n",
            "Confusion Matrix testing:\n",
            "[[6835  280]\n",
            " [ 695  230]]\n",
            "\n",
            "Prediction accuracy testing dataset: 0.8787\n",
            "Prediction recall testing dataset: 0.2486\n",
            "Prediction precision testing dataset: 0.4510\n",
            "Prediction F1 testing dataset: 0.3206\n",
            "AUC-ROC testing dataset: 0.7082\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Model ran\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X, y)                                       # fit the model\n",
        "gnb_pred_t = gnb.predict(X_t)                       # make predictions\n",
        "gnb_score_t = gnb.predict_proba(X_t)                # get prediction scores\n",
        "\n",
        "## accuracy\n",
        "gnb_acc = accuracy_score(y_t, gnb_pred_t)\n",
        "print('Prediction accuracy: {:.4f}'.format(gnb_acc))\n",
        "\n",
        "## recall\n",
        "gnb_recall = recall_score(y_t, gnb_pred_t)\n",
        "print('Prediction recall: {:.4f}'.format(gnb_recall))\n",
        "\n",
        "## precision\n",
        "gnb_precision = precision_score(y_t, gnb_pred_t)\n",
        "print('Prediction precision: {:.4f}'.format(gnb_precision))\n",
        "\n",
        "## F1 score\n",
        "gnb_f1 = f1_score(y_t, gnb_pred_t)\n",
        "print('Prediction F1: {:.4f}'.format(gnb_f1))\n",
        "\n",
        "## AUC-ROC\n",
        "gnb_auc = roc_auc_score(y_t, gnb_score_t[:, 1])\n",
        "print('AUC-ROC : {:.4f}'.format(gnb_auc))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NAwlyqBlzXL",
        "outputId": "be94b5f5-9268-4492-844b-4505e2be27bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction accuracy: 0.7475\n",
            "Prediction recall: 0.6584\n",
            "Prediction precision: 0.2622\n",
            "Prediction F1: 0.3750\n",
            "AUC-ROC : 0.7541\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Model ran\n",
        "log_clf = LogisticRegression()\n",
        "log_clf.fit(X, y)                                        # fit the model\n",
        "log_clf_pred_t = log_clf.predict(X_t)                    # make predictions\n",
        "log_clf_score_t = log_clf.predict_proba(X_t)             # get prediction scores\n",
        "\n",
        "## accuracy\n",
        "log_clf_acc = accuracy_score(y_t, log_clf_pred_t)\n",
        "print('Prediction accuracy testing: {:.4f}'.format(log_clf_acc))\n",
        "\n",
        "## recall\n",
        "log_clf_recall = recall_score(y_t, log_clf_pred_t)\n",
        "print('Prediction recall testing: {:.4f}'.format(log_clf_recall))\n",
        "\n",
        "## precision\n",
        "log_clf_precision = precision_score(y_t, log_clf_pred_t)\n",
        "print('Prediction precision testing: {:.4f}'.format(log_clf_precision))\n",
        "\n",
        "## F1 score\n",
        "log_clf_f1 = f1_score(y_t, log_clf_pred_t)\n",
        "print('Prediction F1 testing: {:.4f}'.format(log_clf_f1))\n",
        "\n",
        "## AUC-ROC\n",
        "log_clf_auc = roc_auc_score(y_t, log_clf_score_t[:, 1])\n",
        "print('AUC-ROC testing: {:.4f}'.format(log_clf_auc))\n",
        "print()\n",
        "\n",
        "# you can use the code below to extract logistic regression's features and their\n",
        "# coefficients; specifically, feature_names_in_ will return all the input features,\n",
        "# and coef_ will return all the features' estimated coefficients\n",
        "log_clf_coef = pd.DataFrame({\n",
        "    'Feature Name': log_clf.feature_names_in_,\n",
        "    'Coefficient': log_clf.coef_[0]\n",
        "})\n",
        "print(log_clf_coef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZbjM4uCl7J2",
        "outputId": "a1beca93-e8be-44c3-cc78-a1aa4712b8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction accuracy testing: 0.8882\n",
            "Prediction recall testing: 0.1492\n",
            "Prediction precision testing: 0.5520\n",
            "Prediction F1 testing: 0.2349\n",
            "AUC-ROC testing: 0.7363\n",
            "\n",
            "      Feature Name  Coefficient\n",
            "0              age     0.001848\n",
            "1          housing    -0.007836\n",
            "2             loan    -0.011205\n",
            "3          contact    -0.136606\n",
            "4         campaign    -0.047964\n",
            "5         previous     0.142368\n",
            "6     emp.var.rate    -0.129525\n",
            "7   cons.price.idx     0.407167\n",
            "8    cons.conf.idx     0.048917\n",
            "9        euribor3m    -0.179989\n",
            "10     nr.employed    -0.007321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explaination for Logistic Regression Coefficients:\n",
        "Age, cons.conf.index have coefficients close to zero but are postitve so the slope is positive.\n",
        "Housing, loan,campaign,nr.employed have coefficients close to zero but are negative so the slope is negative.\n",
        "Contact,emp.var.rate,euribor3m have negative coefficients but there value is less than 0.5 so the slope is not too steep.\n",
        "previous has positive coefficients but the value is less than 0.5 so the slope is not too steep.\n",
        "cons.price.index has the largest coefficient and is positive as well.\n",
        "\n",
        "cons.price.index: we can deduce that for change in one unit of cons.price.index the \"y\" will see an increase by the factor of 0.4 keeping other variables constant.\n",
        "\n",
        "Age:  for change in one unit of Age the \"y\" will see an increase by the factor of 0.0018 keeping other variables constant.\n",
        "\n",
        "Housing:  for change in one unit of Housing the \"y\" will see a decrease by the factor of 0.007 keeping other variables constant.\n",
        "\n",
        "Loan : for change in one unit of Loan the \"y\" will see a decrease by the factor of 0.011 keeping other variables constant.\n",
        "\n",
        "Contact: for change in one unit of contact the \"y\" will see a decrease by the factor of 0.13 keeping other variables constant.\n",
        "\n",
        "Campaign: for change in one unit of campaign the \"y\" will see a decrease by the factor of 0.04 keeping other variables constant.\n",
        "\n",
        "Previous: for change in one unit of previous the \"y\" will see an increase by the factor of 0.14 keeping other variables constant.\n",
        "\n",
        "emp.var.rate: for change in one unit of emp.var.rate the \"y\" will see a decrease by the factor of 0.12 keeping other variables constant.\n",
        "\n",
        "cons.conf.index: for change in one unit of cons.conf.index the \"y\" will see an increase by the factor of 0.04 keeping other variables constant.\n",
        "\n",
        "euribor3m: for change in one unit of euribor3m the \"y\" will see a decrease by the factor of 0.17 keeping other variables constant.\n",
        "\n",
        "nr.employes: for change in one unit of nr.employes the \"y\" will see a decrease by the factor of 0.007 keeping other variables constant.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EzQ5fhc8QSbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,\\\n",
        "    precision_score, f1_score, roc_auc_score\n",
        "\n",
        "# Ran model\n",
        "dt_clf = DecisionTreeClassifier(max_depth=5)\n",
        "dt_clf.fit(X, y)                                    # fit the model\n",
        "dt_clf_pred_t = dt_clf.predict(X_t)                 # make predictions\n",
        "dt_clf_score_t = dt_clf.predict_proba(X_t)          # get prediction scores\n",
        "\n",
        "print(dt_clf_pred_t)\n",
        "\n",
        "print(dt_clf_score_t)\n",
        "\n",
        "## accuracy\n",
        "dt_clf_acc = accuracy_score(y_t, dt_clf_pred_t)\n",
        "print('Prediction accuracy for testing: {:.4f}'.format(dt_clf_acc))\n",
        "\n",
        "## recall\n",
        "dt_clf_recall = recall_score(y_t, dt_clf_pred_t)\n",
        "print('Prediction recall for testing: {:.4f}'.format(dt_clf_recall))\n",
        "\n",
        "## precision\n",
        "dt_clf_precision = precision_score(y_t, dt_clf_pred_t)\n",
        "print('Prediction precision testing: {:.4f}'.format(dt_clf_precision))\n",
        "\n",
        "## F1 score\n",
        "dt_clf_f1 = f1_score(y_t, dt_clf_pred_t)\n",
        "print('Prediction F1 testing: {:.4f}'.format(dt_clf_f1))\n",
        "\n",
        "# auc-roc\n",
        "dt_clf_auc = roc_auc_score(y_t, dt_clf_score_t[:, 1])\n",
        "print('AUC-ROC testing: {:.4f}'.format(dt_clf_auc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3aw3vmRkB6y",
        "outputId": "ae790ff9-169c-42d5-963c-eecd8fa0158b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 ... 0 0 0]\n",
            "[[0.94600321 0.05399679]\n",
            " [0.95990888 0.04009112]\n",
            " [0.4516129  0.5483871 ]\n",
            " ...\n",
            " [0.95990888 0.04009112]\n",
            " [0.94600321 0.05399679]\n",
            " [0.943647   0.056353  ]]\n",
            "Prediction accuracy for testing: 0.8915\n",
            "Prediction recall for testing: 0.2681\n",
            "Prediction precision testing: 0.5598\n",
            "Prediction F1 testing: 0.3626\n",
            "AUC-ROC testing: 0.7629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Summary & Recommendation"
      ],
      "metadata": {
        "id": "UzvZmMI5v-L4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check for imbalance in the dataset to understand if the difference difference in number of people who signed up deposit and number of people who did not sign up is too large and work on methods to reduce the imbalance.\n",
        "\n",
        "Based on the above regression using different methods it is clear that Decision Tree Regression Model provides the highest accuracy but since the dataset suffers from imbalance we should make the decision based on F1-Score which is highest for Naive Bayes(0.375)."
      ],
      "metadata": {
        "id": "LDN3qi0Mwer5"
      }
    }
  ]
}