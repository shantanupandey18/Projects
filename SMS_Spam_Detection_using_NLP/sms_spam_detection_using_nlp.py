# -*- coding: utf-8 -*-
"""SMS_Spam_Detection_using_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dTbSXAZIR2EqLH6ojYtznEYBGBdL7KhD

## Section 0: Download SMS Spam Dataset
We will be working with the [SMS Spam Dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) provided by the UCI machine learning repository.

Fighting spams is a critical task for many mobile service providers. However, such a task is challenging because of the complexity of natural language. We will apply the natural language processing techniques to build a classifier that can accurately predict whether an SMS text is a spam or not.

Download two text files, namely `spam-train.csv` and `spam-test.csv`. The `spam-train.txt` includes the text of multiple SMS messages as well as their labels (1 for spam and 0 for non-spam). The `spam-test.txt` includes text and labels for another set of SMS messages. Some example data points are listed as follows:
```
label	text
0		Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...
1		FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv
0		As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune
1		WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.
1		Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030

```
"""

from urllib.request import urlretrieve
urlretrieve('https://drive.google.com/uc?export=download&id=1VRKLGMIJZjGmSJQMCE_Ukn7WnY4M2q07',
            'spam-train.csv')
urlretrieve('https://drive.google.com/uc?export=download&id=1p4CBU3VSZOjiCeupL4UhIjbJb-bB-Ju5',
            'spam-test.csv')

"""## Section 1: Import Data
Import both `spam-train.csv` and `spam-test.csv`. Create a DataFrame `spam_train` to store the data from `spam-train.csv` and create another DataFrame `spam_test` to store the data from `spam-test.csv`. Report how many SMS messages each csv file has.
"""

import pandas as pd
# read lines from the txt file and extract all the reviews
# read spam_train csv
spam_train = pd.read_csv ('spam-train.csv')
print(spam_train)

# read spam_test csv
spam_test = pd.read_csv ('spam-test.csv')
print(spam_test)

""":## Section 2.1: Preprocess Text Data
In this section, preprocessing the SMS text data in both `spam-train.csv` and `spam-test.csv`. The code tokenizes each SMS text, lowercase each token, remove punctuations and stop words, and conduct stemming for each remaining token.
"""

train_msgs = spam_train.iloc[:, 1]
test_msgs = spam_test.iloc[:, 1]


## download the punkt module
import nltk
nltk.download('punkt')

## get punctuations
import string
punctuations = string.punctuation

## download stop words
from nltk.corpus import stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

## import stemmer
from nltk.stem import PorterStemmer
ps = PorterStemmer()

## iteratively process each SMS message in spam-train.csv
new_train_msgs = []
review_tokenized_list = []
review_lowercased = []
review_tokenized_lowercase_list = []
print('Result for nltk tokenization:')
for msg in train_msgs:
    ## TODO: insert your code here to process each message in the spam-train.csv
    review_tokenized_list.append(nltk.word_tokenize(msg))
    review_lowercased.append(msg.lower())


for labels in review_lowercased:
    review_tokenized_lowercase_list.append(nltk.word_tokenize(labels))

review_no_punctuations_words = []
review_no_punctuations_list = []
for words in review_tokenized_lowercase_list:
    for word in words:
        if word not in string.punctuation:
            review_no_punctuations_words.append(word)
    review_no_punctuations_list.append(review_no_punctuations_words)
    review_no_punctuations_words = []

# remove stop words
stop_words = set(stopwords.words('english'))
review_no_stopwords = []
review_no_stopwords_list = []
for label in review_no_punctuations_list:
    for word in label:
      if word not in stop_words:
          review_no_stopwords.append(word)
    review_no_stopwords_list.append(review_no_stopwords)
    review_no_stopwords = []

# stemming the text
review_stemmed = []
review_stemmed_list_train = []
for token in review_no_stopwords_list:
  for word in token:
    review_stemmed.append(ps.stem(word))
  review_stemmed_list_train.append(review_stemmed)
  review_stemmed = []

### append the processed review into new list
final_string_train = []
for strings in review_stemmed_list_train:
    review_processed_string = " ".join(strings)
    final_string_train.append(review_processed_string)
    review_processed_string = ""


print(review_tokenized_list)
print(review_lowercased)
print(review_tokenized_lowercase_list)
print(review_no_punctuations_list)
print(review_no_stopwords_list)
print(review_stemmed_list_train)
print(final_string_train)

## iteratively process each SMS message in spam-test.csv
new_test_msgs = []
review_tokenized_list = []
review_lowercased = []
review_tokenized_lowercase_list = []
print('Result for nltk tokenization:')
for msg in test_msgs:
    ## TODO: insert your code here to process each message in the spam-train.csv
    review_tokenized_list.append(nltk.word_tokenize(msg))
    review_lowercased.append(msg.lower())

for labels in review_lowercased:
    review_tokenized_lowercase_list.append(nltk.word_tokenize(labels))

review_no_punctuations_words = []
review_no_punctuations_list = []
for words in review_tokenized_lowercase_list:
    for word in words:
        if word not in string.punctuation:
            review_no_punctuations_words.append(word)
    review_no_punctuations_list.append(review_no_punctuations_words)
    review_no_punctuations_words = []

# remove stop words
stop_words = set(stopwords.words('english'))
review_no_stopwords = []
review_no_stopwords_list = []
for label in review_no_punctuations_list:
    for word in label:
      if word not in stop_words:
          review_no_stopwords.append(word)
    review_no_stopwords_list.append(review_no_stopwords)
    review_no_stopwords = []

# stemming the text
review_stemmed = []
review_stemmed_list_test = []
for token in review_no_stopwords_list:
  for word in token:
    review_stemmed.append(ps.stem(word))
  review_stemmed_list_test.append(review_stemmed)
  review_stemmed = []


### append the processed review into new list
final_string_test = []
for lists in review_stemmed_list_test:
    review_processed_string = " ".join(lists)
    final_string_test.append(review_processed_string)
    review_processed_string = ""



print(review_tokenized_list)
print(review_lowercased)
print(review_tokenized_lowercase_list)
print(review_no_punctuations_list)
print(review_no_stopwords_list)
print(review_stemmed_list_test)
print(final_string_test)

"""## Section 2.2: Convert Text Data with TF-IDF
After data preprocessing, the next step is to convert each SMS message into a numerical vector using TF-IDF.

"""

# we can apply TfidfVectorizer function to extract TF-IDF vectors for each message
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_transformer = TfidfVectorizer(max_features=500)

# TODO: replace the question marks '?' with the correct variables you created in Section 2.1
tfidf_transformer.fit(final_string_train)
train_features = tfidf_transformer.transform(final_string_train).toarray()
test_features = tfidf_transformer.transform(final_string_test).toarray()

print(train_features)
print(test_features)

"""## Section 3: Apply Machine Learning to Combat Spam Messages
In this section, we need to train a logistic regression model & Naive Bayes classifier to predict whether a given SMS message is a spam message or not. Specifically, we need to use the TF-IDF vectors of the training dataset (`train_features`) to train the classifier and use the TF-IDF vectors of the test dataset (`test_features`) for prediction. Once the prediction is finished, we report the F1 score and AUC-ROC on the test dataset for the Naive Bayes classifier.




"""

"""
 Logistic Regression
"""
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score

log_clf = LogisticRegression()
log_clf.fit(train_features, spam_train['label'])        # fit the model
log_clf_pred = log_clf.predict(test_features)           # make predictions
log_clf_score = log_clf.predict_proba(test_features)    # get prediction scores

## F1 score
log_clf_f1 = f1_score(spam_test['label'], log_clf_pred)
print('Prediction F1: {:.4f}'.format(log_clf_f1))

## AUC-ROC
log_clf_auc = roc_auc_score(spam_test['label'], log_clf_score[:, 1])
print('AUC-ROC : {:.4f}'.format(log_clf_auc))
print()

# Logistic regression features
log_clf_coef = pd.DataFrame({
    'Feature Name': tfidf_transformer.get_feature_names_out(),
    'Coefficient': log_clf.coef_[0]
})
print(log_clf_coef)

'''
Naive Bayes Model
'''
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,\
    precision_score, f1_score, roc_auc_score

# Model ran
gnb = GaussianNB()
gnb.fit(train_features, spam_train['label'])                  # fit the model
gnb_pred_t = gnb.predict(test_features)                       # make predictions
gnb_score_t = gnb.predict_proba(test_features)                # get prediction scores

## accuracy
gnb_acc = accuracy_score(spam_test['label'], gnb_pred_t)
print('Prediction accuracy: {:.4f}'.format(gnb_acc))

## recall
gnb_recall = recall_score(spam_test['label'], gnb_pred_t)
print('Prediction recall: {:.4f}'.format(gnb_recall))

## precision
gnb_precision = precision_score(spam_test['label'], gnb_pred_t)
print('Prediction precision: {:.4f}'.format(gnb_precision))

## F1 score
gnb_f1 = f1_score(spam_test['label'], gnb_pred_t)
print('Prediction F1: {:.4f}'.format(gnb_f1))

## AUC-ROC
gnb_auc = roc_auc_score(spam_test['label'], gnb_score_t[:, 1])
print('AUC-ROC : {:.4f}'.format(gnb_auc))
print()